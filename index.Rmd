--- 
title: "Catal Image Vision API Tests"
author: "Claudia A Engel"
date: "Last updated: `r format(Sys.time(), '%B %d, %Y')`"
site: bookdown::bookdown_site
output: bookdown::gitbook
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
github-repo: cengel/Catal-Vision-API
description: "Tests of Catal images with vision cloud APIs to describe content"
---


# Intro {-}

We randomly sampled 1000 images out of the ~138k that are currently accessioned into [SDR](https://sdr.stanford.edu) and generated labels using the [Google Vision](https://cloud.google.com/vision/) API [**GV**][^1] and the [Clarifai Predict](https://clarifai.com/demo) API [**CP**].  

[^1]: Many thanks to Peter Mangiafico.

Code to generate **GV** labels is here: https://github.com/sul-dlss-labs/google-vision-ai

Catal project is here: http://catalhoyuk.com

SUL AI studio: https://sites.google.com/stanford.edu/sul-ai-studio/

SUL AI studio talk is [here](https://docs.google.com/presentation/d/1pey1CBb6c4hAIot1YR0r4FNwQFEY6DXCjkNKZvA53l4/edit?usp=sharing). 

For various reasons we had some attrition and ended up with 766 images. Results shown here are based on those.

## Comments, ideas in random order

- It could be useful for discoverability if the images are embedded in a much larger dataset, but not sure about within the image dataset itself.

- Instead of looking for positive identification turn it around and look for things that are *NOT* excavation or artifacts. For example, 'buildig' gets us images of the shelter, so allows us to weed out relevant images(?). 

- Combine several labels to separate people (man, woman, person, group, ...) from buildings (soil, wall, dirt, ...) from X-finds etc.

- Use *GV_OCR* to identify images with whiteboards, though the rendered text is not very usable.